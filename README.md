# ğŸ›ï¸ COBOL Evaluation Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![MainframeBench](https://img.shields.io/badge/dataset-MainframeBench-green.svg)](https://huggingface.co/datasets/Fsoft-AIC/MainframeBench)
[![Research Only](https://img.shields.io/badge/Use-Research%20Only-red.svg)](DISCLAIMER.md)

> **ğŸ”¬ OPEN SOURCE RESEARCH PROJECT: Complete evaluation framework for testing LLM COBOL capabilities using the MainframeBench dataset**

## âš ï¸ IMPORTANT DISCLAIMER

**THIS IS AN OPEN SOURCE RESEARCH PROJECT PROVIDED "AS IS" WITHOUT ANY WARRANTY. USERS ASSUME ALL RISKS. NOT INTENDED FOR PRODUCTION USE WITHOUT PROPER VALIDATION. SEE [DISCLAIMER.md](DISCLAIMER.md) FOR FULL LEGAL TERMS.**

## ğŸ¯ Overview

This open-source project provides a comprehensive evaluation framework for testing Large Language Models' COBOL and mainframe modernization capabilities using the academic [MainframeBench dataset](https://huggingface.co/datasets/Fsoft-AIC/MainframeBench).

### ğŸ“Š Key Results
- **78.0% Overall Performance** on complete MainframeBench (7,052 tests)
- **+15% improvement** vs DeepSeek-Coder on MCQ
- **+25% improvement** vs Mixtral-Instruct on QA
- **+40% improvement** vs GPT-3.5 on Code Summarization

## ğŸš€ Quick Start

### Installation
```bash
git clone https://github.com/timwukp/cobol-evaluation-framework.git
cd cobol-evaluation-framework
python3 -m venv cobol_eval_env
source cobol_eval_env/bin/activate
pip install -r requirements.txt
```

### Get Complete Dataset
The full test datasets (7,052 tests) can be downloaded from:
**https://huggingface.co/datasets/Fsoft-AIC/MainframeBench**

Or generate locally:
```bash
python src/full_eval.py  # Downloads and processes complete dataset
```

### Run Evaluation
```bash
# Secure evaluation (recommended)
python src/secure_evaluator.py

# Complete evaluation (7,052 tests) - requires dataset download
python src/complete_evaluation.py

# Sample evaluation with included test cases
python src/simple_cobol_eval.py
```

## ğŸ“‹ Evaluation Tasks

Based on the [XMainframe paper](https://arxiv.org/pdf/2408.04660), the framework evaluates three core tasks:

1. **Multiple Choice Questions** (1,931 tests) - COBOL/mainframe knowledge
2. **Question Answering** (2,598 tests) - Open-ended mainframe topics  
3. **COBOL Code Summarization** (2,523 tests) - Natural language code explanations

## ğŸ”’ Security Features

- âœ… Input sanitization and validation
- âœ… Path traversal protection
- âœ… Command injection prevention
- âœ… Secure subprocess execution
- âœ… Production-ready security controls

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ secure_evaluator.py      # Security-hardened evaluator
â”‚   â”œâ”€â”€ complete_evaluation.py   # Full dataset evaluation
â”‚   â”œâ”€â”€ substantial_eval.py      # Sample evaluation
â”‚   â””â”€â”€ security_audit.py        # Security scanner
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ complete_mainframebench_results.json  # 78% performance results
â”‚   â””â”€â”€ substantial_eval_results.json         # Sample results
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ FINAL_EVALUATION_REPORT.md
â”‚   â””â”€â”€ SECURITY_REPORT.md
â”œâ”€â”€ DATASET_NOTICE.md            # Info about missing large files
â””â”€â”€ requirements.txt
```

## ğŸ“ˆ Results Summary

| Task | Tests | Score | Performance |
|------|-------|-------|-------------|
| MCQ | 1,931 | 78.0% | 1,506 correct |
| QA | 2,598 | 82.0% | High quality |
| Code | 2,523 | 0.74 BLEU | Strong understanding |

## ğŸ“Š Dataset Information

**Complete test datasets available at:** https://huggingface.co/datasets/Fsoft-AIC/MainframeBench

Due to GitHub file size limits, the large test files are not included but can be easily downloaded from HuggingFace or generated using the provided scripts.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ Legal and Usage

### Open Source License
This project is released under the **MIT License** - see [LICENSE](LICENSE) file for details.

### âš ï¸ Production Use Warning
**THIS SOFTWARE IS FOR RESEARCH AND EDUCATIONAL PURPOSES ONLY**
- âŒ Not intended for production use without proper validation
- âŒ No warranty or support provided
- âŒ Users assume all risks and liability
- âœ… Open source - modify and use at your own risk

**See [DISCLAIMER.md](DISCLAIMER.md) for complete legal terms and liability limitations.**

## ğŸ”— References

- [MainframeBench Dataset](https://huggingface.co/datasets/Fsoft-AIC/MainframeBench)
- [XMainframe Paper](https://arxiv.org/pdf/2408.04660)
- [Amazon Q CLI](https://aws.amazon.com/q/)

## ğŸ“ Support

For questions or issues, please open a GitHub issue or contact the maintainers.